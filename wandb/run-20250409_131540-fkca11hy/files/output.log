  0%|          | 0/18036 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/mnt/petrelfs/majiachen/project/mllm-safety-cot/src/sft_vlm_cot.py", line 174, in <module>
    trainer.train()
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 3740, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/accelerate/accelerator.py", line 2321, in backward
    self.deepspeed_engine_wrapped.backward(loss, **kwargs)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 275, in backward
    self.engine.step()
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2249, in step
    self._take_model_step(lr_kwargs)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2152, in _take_model_step
    self.optimizer.step()
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1887, in step
    single_grad_partition = self.flatten_dense_tensors_aligned(
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 931, in flatten_dense_tensors_aligned
    return self.flatten(align_dense_tensors(tensor_list, alignment))
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/torch/_utils.py", line 519, in _flatten_dense_tensors
    return torch._C._nn.flatten_dense_tensors(tensors)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 15.44 GiB. GPU 0 has a total capacity of 79.32 GiB of which 1.00 GiB is free. Including non-PyTorch memory, this process has 78.32 GiB memory in use. Of the allocated memory 61.80 GiB is allocated by PyTorch, and 15.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mnt/petrelfs/majiachen/project/mllm-safety-cot/src/sft_vlm_cot.py", line 174, in <module>
[rank0]:     trainer.train()
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 3740, in training_step
[rank0]:     self.accelerator.backward(loss, **kwargs)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/accelerate/accelerator.py", line 2321, in backward
[rank0]:     self.deepspeed_engine_wrapped.backward(loss, **kwargs)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 275, in backward
[rank0]:     self.engine.step()
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2249, in step
[rank0]:     self._take_model_step(lr_kwargs)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2152, in _take_model_step
[rank0]:     self.optimizer.step()
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 1887, in step
[rank0]:     single_grad_partition = self.flatten_dense_tensors_aligned(
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 931, in flatten_dense_tensors_aligned
[rank0]:     return self.flatten(align_dense_tensors(tensor_list, alignment))
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/torch/_utils.py", line 519, in _flatten_dense_tensors
[rank0]:     return torch._C._nn.flatten_dense_tensors(tensors)
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 15.44 GiB. GPU 0 has a total capacity of 79.32 GiB of which 1.00 GiB is free. Including non-PyTorch memory, this process has 78.32 GiB memory in use. Of the allocated memory 61.80 GiB is allocated by PyTorch, and 15.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
