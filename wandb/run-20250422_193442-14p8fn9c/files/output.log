  0%|          | 0/2340 [00:00<?, ?it/s]It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.
  9%|▊         | 200/2340 [02:03<21:16,  1.68it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 2.5449, 'grad_norm': 10.905336380004883, 'learning_rate': 1.9923076923076926e-05, 'mean_token_accuracy': 0.5378891110420227, 'epoch': 0.01}
{'loss': 2.006, 'grad_norm': 7.3852643966674805, 'learning_rate': 1.983760683760684e-05, 'mean_token_accuracy': 0.5535835713148117, 'epoch': 0.03}
{'loss': 1.7585, 'grad_norm': 7.003392219543457, 'learning_rate': 1.9752136752136755e-05, 'mean_token_accuracy': 0.5877996802330017, 'epoch': 0.04}
{'loss': 1.6191, 'grad_norm': 2.818432331085205, 'learning_rate': 1.9666666666666666e-05, 'mean_token_accuracy': 0.6061239361763, 'epoch': 0.05}
{'loss': 1.6291, 'grad_norm': 5.789332866668701, 'learning_rate': 1.9581196581196584e-05, 'mean_token_accuracy': 0.6074100971221924, 'epoch': 0.06}
{'loss': 1.5245, 'grad_norm': 2.836648941040039, 'learning_rate': 1.9495726495726498e-05, 'mean_token_accuracy': 0.6156576573848724, 'epoch': 0.08}
{'loss': 1.4475, 'grad_norm': 1.8738058805465698, 'learning_rate': 1.9410256410256413e-05, 'mean_token_accuracy': 0.6281286120414734, 'epoch': 0.09}
{'loss': 1.4101, 'grad_norm': 2.655773639678955, 'learning_rate': 1.9324786324786327e-05, 'mean_token_accuracy': 0.6331615686416626, 'epoch': 0.1}
{'loss': 1.4109, 'grad_norm': 2.8193960189819336, 'learning_rate': 1.923931623931624e-05, 'mean_token_accuracy': 0.6334860622882843, 'epoch': 0.12}
{'loss': 1.4121, 'grad_norm': 2.952824115753174, 'learning_rate': 1.9153846153846156e-05, 'mean_token_accuracy': 0.6324463009834289, 'epoch': 0.13}
{'loss': 1.3846, 'grad_norm': 2.48291015625, 'learning_rate': 1.906837606837607e-05, 'mean_token_accuracy': 0.630318409204483, 'epoch': 0.14}
{'loss': 1.3629, 'grad_norm': 4.199333667755127, 'learning_rate': 1.8982905982905985e-05, 'mean_token_accuracy': 0.6425345361232757, 'epoch': 0.15}
{'loss': 1.3195, 'grad_norm': 3.075483560562134, 'learning_rate': 1.88974358974359e-05, 'mean_token_accuracy': 0.6411087095737458, 'epoch': 0.17}
{'loss': 1.3075, 'grad_norm': 2.9823250770568848, 'learning_rate': 1.8811965811965813e-05, 'mean_token_accuracy': 0.6507839262485504, 'epoch': 0.18}
{'loss': 1.3361, 'grad_norm': 2.9936835765838623, 'learning_rate': 1.8726495726495728e-05, 'mean_token_accuracy': 0.6431928396224975, 'epoch': 0.19}
{'loss': 1.2648, 'grad_norm': 2.5142571926116943, 'learning_rate': 1.8641025641025642e-05, 'mean_token_accuracy': 0.6499781370162964, 'epoch': 0.21}
{'loss': 1.2548, 'grad_norm': 3.05672025680542, 'learning_rate': 1.8555555555555557e-05, 'mean_token_accuracy': 0.6473025262355805, 'epoch': 0.22}
{'loss': 1.2544, 'grad_norm': 3.5518393516540527, 'learning_rate': 1.847008547008547e-05, 'mean_token_accuracy': 0.6490391254425049, 'epoch': 0.23}
{'loss': 1.2175, 'grad_norm': 3.71028733253479, 'learning_rate': 1.8384615384615386e-05, 'mean_token_accuracy': 0.6509364724159241, 'epoch': 0.24}
{'loss': 1.2591, 'grad_norm': 2.9231531620025635, 'learning_rate': 1.82991452991453e-05, 'mean_token_accuracy': 0.6486575305461884, 'epoch': 0.26}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 17%|█▋        | 400/2340 [04:12<19:00,  1.70it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 1.209, 'grad_norm': 2.9559059143066406, 'learning_rate': 1.8213675213675214e-05, 'mean_token_accuracy': 0.6600054442882538, 'epoch': 0.27}
{'loss': 1.1831, 'grad_norm': 3.240056276321411, 'learning_rate': 1.812820512820513e-05, 'mean_token_accuracy': 0.6562431693077088, 'epoch': 0.28}
{'loss': 1.2286, 'grad_norm': 3.4445860385894775, 'learning_rate': 1.8042735042735043e-05, 'mean_token_accuracy': 0.6541555285453796, 'epoch': 0.29}
{'loss': 1.1564, 'grad_norm': 2.850919485092163, 'learning_rate': 1.7957264957264958e-05, 'mean_token_accuracy': 0.6681105434894562, 'epoch': 0.31}
{'loss': 1.2229, 'grad_norm': 2.6409692764282227, 'learning_rate': 1.7871794871794875e-05, 'mean_token_accuracy': 0.6536325335502624, 'epoch': 0.32}
{'loss': 1.2122, 'grad_norm': 3.211911201477051, 'learning_rate': 1.7786324786324787e-05, 'mean_token_accuracy': 0.6561647117137909, 'epoch': 0.33}
{'loss': 1.1187, 'grad_norm': 3.05082106590271, 'learning_rate': 1.77008547008547e-05, 'mean_token_accuracy': 0.6677075147628784, 'epoch': 0.35}
{'loss': 1.095, 'grad_norm': 3.349605083465576, 'learning_rate': 1.7615384615384615e-05, 'mean_token_accuracy': 0.6732338607311249, 'epoch': 0.36}
{'loss': 1.1032, 'grad_norm': 4.418694496154785, 'learning_rate': 1.752991452991453e-05, 'mean_token_accuracy': 0.6777380645275116, 'epoch': 0.37}
{'loss': 1.1236, 'grad_norm': 3.861877918243408, 'learning_rate': 1.7444444444444448e-05, 'mean_token_accuracy': 0.6667681992053985, 'epoch': 0.38}
{'loss': 1.0692, 'grad_norm': 3.8560519218444824, 'learning_rate': 1.7358974358974362e-05, 'mean_token_accuracy': 0.67746302485466, 'epoch': 0.4}
{'loss': 1.0999, 'grad_norm': 3.297773599624634, 'learning_rate': 1.7273504273504276e-05, 'mean_token_accuracy': 0.6707960963249207, 'epoch': 0.41}
{'loss': 1.0711, 'grad_norm': 10.865224838256836, 'learning_rate': 1.718803418803419e-05, 'mean_token_accuracy': 0.6803491771221161, 'epoch': 0.42}
{'loss': 1.0541, 'grad_norm': 4.131566047668457, 'learning_rate': 1.7102564102564102e-05, 'mean_token_accuracy': 0.678935194015503, 'epoch': 0.44}
{'loss': 1.0798, 'grad_norm': 3.120508909225464, 'learning_rate': 1.7017094017094016e-05, 'mean_token_accuracy': 0.6793932378292084, 'epoch': 0.45}
{'loss': 1.0438, 'grad_norm': 4.210508823394775, 'learning_rate': 1.6931623931623934e-05, 'mean_token_accuracy': 0.6787242352962494, 'epoch': 0.46}
{'loss': 1.1016, 'grad_norm': 3.9325268268585205, 'learning_rate': 1.684615384615385e-05, 'mean_token_accuracy': 0.6810755372047425, 'epoch': 0.47}
{'loss': 1.0722, 'grad_norm': 3.4970309734344482, 'learning_rate': 1.6760683760683763e-05, 'mean_token_accuracy': 0.6781593441963196, 'epoch': 0.49}
{'loss': 1.0163, 'grad_norm': 5.081149578094482, 'learning_rate': 1.6675213675213677e-05, 'mean_token_accuracy': 0.68820760846138, 'epoch': 0.5}
{'loss': 1.0648, 'grad_norm': 5.76625394821167, 'learning_rate': 1.6589743589743592e-05, 'mean_token_accuracy': 0.676859849691391, 'epoch': 0.51}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 26%|██▌       | 600/2340 [06:22<17:24,  1.67it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 1.0691, 'grad_norm': 4.069534778594971, 'learning_rate': 1.6504273504273506e-05, 'mean_token_accuracy': 0.6791943609714508, 'epoch': 0.53}
{'loss': 1.0035, 'grad_norm': 4.7394866943359375, 'learning_rate': 1.641880341880342e-05, 'mean_token_accuracy': 0.6886982858181, 'epoch': 0.54}
{'loss': 1.0349, 'grad_norm': 4.981570243835449, 'learning_rate': 1.6333333333333335e-05, 'mean_token_accuracy': 0.6867599308490753, 'epoch': 0.55}
{'loss': 0.9693, 'grad_norm': 3.04154896736145, 'learning_rate': 1.624786324786325e-05, 'mean_token_accuracy': 0.6979094386100769, 'epoch': 0.56}
{'loss': 1.019, 'grad_norm': 3.3315207958221436, 'learning_rate': 1.6162393162393164e-05, 'mean_token_accuracy': 0.6817128658294678, 'epoch': 0.58}
{'loss': 0.9617, 'grad_norm': 4.993558883666992, 'learning_rate': 1.607692307692308e-05, 'mean_token_accuracy': 0.6863764762878418, 'epoch': 0.59}
{'loss': 0.9733, 'grad_norm': 3.027376890182495, 'learning_rate': 1.5991452991452993e-05, 'mean_token_accuracy': 0.6910835206508636, 'epoch': 0.6}
{'loss': 0.9926, 'grad_norm': 2.947821855545044, 'learning_rate': 1.5905982905982907e-05, 'mean_token_accuracy': 0.6854314386844635, 'epoch': 0.62}
{'loss': 0.9379, 'grad_norm': 5.3793134689331055, 'learning_rate': 1.582051282051282e-05, 'mean_token_accuracy': 0.6964565277099609, 'epoch': 0.63}
{'loss': 0.9058, 'grad_norm': 4.046835422515869, 'learning_rate': 1.5735042735042736e-05, 'mean_token_accuracy': 0.7071600198745728, 'epoch': 0.64}
{'loss': 0.8783, 'grad_norm': 3.7635419368743896, 'learning_rate': 1.564957264957265e-05, 'mean_token_accuracy': 0.7101707398891449, 'epoch': 0.65}
{'loss': 0.9079, 'grad_norm': 3.0286076068878174, 'learning_rate': 1.5564102564102565e-05, 'mean_token_accuracy': 0.7010087132453918, 'epoch': 0.67}
{'loss': 0.9768, 'grad_norm': 3.6707777976989746, 'learning_rate': 1.547863247863248e-05, 'mean_token_accuracy': 0.693753319978714, 'epoch': 0.68}
{'loss': 0.9793, 'grad_norm': 5.359778881072998, 'learning_rate': 1.5393162393162394e-05, 'mean_token_accuracy': 0.6912063419818878, 'epoch': 0.69}
{'loss': 0.9325, 'grad_norm': 3.6574220657348633, 'learning_rate': 1.5307692307692308e-05, 'mean_token_accuracy': 0.7055705845355987, 'epoch': 0.71}
{'loss': 0.919, 'grad_norm': 4.076463222503662, 'learning_rate': 1.5222222222222223e-05, 'mean_token_accuracy': 0.6910646438598633, 'epoch': 0.72}
{'loss': 0.924, 'grad_norm': 2.8197782039642334, 'learning_rate': 1.5136752136752137e-05, 'mean_token_accuracy': 0.6911457240581512, 'epoch': 0.73}
{'loss': 0.9744, 'grad_norm': 3.7195382118225098, 'learning_rate': 1.5051282051282053e-05, 'mean_token_accuracy': 0.6890603959560394, 'epoch': 0.74}
{'loss': 0.8816, 'grad_norm': 4.437056064605713, 'learning_rate': 1.4965811965811968e-05, 'mean_token_accuracy': 0.7079899132251739, 'epoch': 0.76}
{'loss': 0.9045, 'grad_norm': 3.3347420692443848, 'learning_rate': 1.4880341880341882e-05, 'mean_token_accuracy': 0.7022351086139679, 'epoch': 0.77}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 34%|███▍      | 800/2340 [08:33<15:16,  1.68it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.901, 'grad_norm': 5.2149434089660645, 'learning_rate': 1.4794871794871796e-05, 'mean_token_accuracy': 0.700518524646759, 'epoch': 0.78}
{'loss': 0.8864, 'grad_norm': 2.8190696239471436, 'learning_rate': 1.4709401709401712e-05, 'mean_token_accuracy': 0.7045165717601776, 'epoch': 0.79}
{'loss': 0.8932, 'grad_norm': 5.720264434814453, 'learning_rate': 1.4623931623931623e-05, 'mean_token_accuracy': 0.7081719398498535, 'epoch': 0.81}
{'loss': 0.8585, 'grad_norm': 3.3088490962982178, 'learning_rate': 1.453846153846154e-05, 'mean_token_accuracy': 0.7117078542709351, 'epoch': 0.82}
{'loss': 0.9536, 'grad_norm': 3.8042242527008057, 'learning_rate': 1.4452991452991454e-05, 'mean_token_accuracy': 0.6954591810703278, 'epoch': 0.83}
{'loss': 0.8911, 'grad_norm': 2.545412540435791, 'learning_rate': 1.4367521367521368e-05, 'mean_token_accuracy': 0.7026668965816498, 'epoch': 0.85}
{'loss': 0.9013, 'grad_norm': 4.364256858825684, 'learning_rate': 1.4282051282051283e-05, 'mean_token_accuracy': 0.703830748796463, 'epoch': 0.86}
{'loss': 0.8746, 'grad_norm': 3.080575466156006, 'learning_rate': 1.4196581196581199e-05, 'mean_token_accuracy': 0.7116102337837219, 'epoch': 0.87}
{'loss': 0.9508, 'grad_norm': 4.217307090759277, 'learning_rate': 1.4111111111111113e-05, 'mean_token_accuracy': 0.6968701958656311, 'epoch': 0.88}
{'loss': 0.8831, 'grad_norm': 5.919216156005859, 'learning_rate': 1.4025641025641026e-05, 'mean_token_accuracy': 0.7059168696403504, 'epoch': 0.9}
{'loss': 0.8317, 'grad_norm': 7.111822605133057, 'learning_rate': 1.394017094017094e-05, 'mean_token_accuracy': 0.710429847240448, 'epoch': 0.91}
{'loss': 0.9358, 'grad_norm': 4.882777214050293, 'learning_rate': 1.3854700854700855e-05, 'mean_token_accuracy': 0.7056341111660004, 'epoch': 0.92}
{'loss': 0.9181, 'grad_norm': 5.775094032287598, 'learning_rate': 1.3769230769230771e-05, 'mean_token_accuracy': 0.6979376077651978, 'epoch': 0.94}
{'loss': 0.8592, 'grad_norm': 4.817023754119873, 'learning_rate': 1.3683760683760686e-05, 'mean_token_accuracy': 0.7113731861114502, 'epoch': 0.95}
{'loss': 0.934, 'grad_norm': 4.267448425292969, 'learning_rate': 1.35982905982906e-05, 'mean_token_accuracy': 0.7032367348670959, 'epoch': 0.96}
{'loss': 0.8955, 'grad_norm': 15.501077651977539, 'learning_rate': 1.3512820512820514e-05, 'mean_token_accuracy': 0.704038017988205, 'epoch': 0.97}
{'loss': 0.8147, 'grad_norm': 6.200721740722656, 'learning_rate': 1.3427350427350427e-05, 'mean_token_accuracy': 0.7177831768989563, 'epoch': 0.99}
{'loss': 0.8618, 'grad_norm': 3.2875304222106934, 'learning_rate': 1.3341880341880342e-05, 'mean_token_accuracy': 0.7096608996391296, 'epoch': 1.0}
{'loss': 0.9146, 'grad_norm': 6.078082084655762, 'learning_rate': 1.3256410256410258e-05, 'mean_token_accuracy': 0.7003265917301178, 'epoch': 1.01}
{'loss': 0.7917, 'grad_norm': 2.993131160736084, 'learning_rate': 1.3170940170940172e-05, 'mean_token_accuracy': 0.720000046491623, 'epoch': 1.03}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 43%|████▎     | 1000/2340 [10:43<13:27,  1.66it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.8211, 'grad_norm': 3.5838911533355713, 'learning_rate': 1.3085470085470086e-05, 'mean_token_accuracy': 0.7226434409618377, 'epoch': 1.04}
{'loss': 0.9023, 'grad_norm': 2.934399127960205, 'learning_rate': 1.3000000000000001e-05, 'mean_token_accuracy': 0.702851003408432, 'epoch': 1.05}
{'loss': 0.841, 'grad_norm': 2.9914636611938477, 'learning_rate': 1.2914529914529917e-05, 'mean_token_accuracy': 0.7110096335411071, 'epoch': 1.06}
{'loss': 0.7642, 'grad_norm': 6.140730381011963, 'learning_rate': 1.2829059829059831e-05, 'mean_token_accuracy': 0.7345186531543731, 'epoch': 1.08}
{'loss': 0.8361, 'grad_norm': 3.225446939468384, 'learning_rate': 1.2743589743589744e-05, 'mean_token_accuracy': 0.714986777305603, 'epoch': 1.09}
{'loss': 0.7908, 'grad_norm': 2.530517339706421, 'learning_rate': 1.2658119658119659e-05, 'mean_token_accuracy': 0.7196804463863373, 'epoch': 1.1}
{'loss': 0.9374, 'grad_norm': 3.341954469680786, 'learning_rate': 1.2572649572649573e-05, 'mean_token_accuracy': 0.7020796120166779, 'epoch': 1.12}
{'loss': 0.8719, 'grad_norm': 4.224591255187988, 'learning_rate': 1.2487179487179487e-05, 'mean_token_accuracy': 0.7046438992023468, 'epoch': 1.13}
{'loss': 0.9167, 'grad_norm': 9.699039459228516, 'learning_rate': 1.2401709401709404e-05, 'mean_token_accuracy': 0.7096818387508392, 'epoch': 1.14}
{'loss': 0.8344, 'grad_norm': 4.080440998077393, 'learning_rate': 1.2316239316239318e-05, 'mean_token_accuracy': 0.7106167137622833, 'epoch': 1.15}
{'loss': 0.8133, 'grad_norm': 3.2110531330108643, 'learning_rate': 1.2230769230769232e-05, 'mean_token_accuracy': 0.7190372109413147, 'epoch': 1.17}
{'loss': 0.9379, 'grad_norm': 2.835925340652466, 'learning_rate': 1.2145299145299145e-05, 'mean_token_accuracy': 0.7032559514045715, 'epoch': 1.18}
{'loss': 0.7765, 'grad_norm': 6.087150573730469, 'learning_rate': 1.205982905982906e-05, 'mean_token_accuracy': 0.722200071811676, 'epoch': 1.19}
{'loss': 0.7904, 'grad_norm': 4.384492874145508, 'learning_rate': 1.1974358974358976e-05, 'mean_token_accuracy': 0.7282692432403565, 'epoch': 1.21}
{'loss': 0.7548, 'grad_norm': 6.173615455627441, 'learning_rate': 1.188888888888889e-05, 'mean_token_accuracy': 0.7287349104881287, 'epoch': 1.22}
{'loss': 0.84, 'grad_norm': 2.7802932262420654, 'learning_rate': 1.1803418803418804e-05, 'mean_token_accuracy': 0.7099308133125305, 'epoch': 1.23}
{'loss': 0.8003, 'grad_norm': 10.67021369934082, 'learning_rate': 1.1717948717948719e-05, 'mean_token_accuracy': 0.7245097458362579, 'epoch': 1.24}
{'loss': 0.8431, 'grad_norm': 4.001161575317383, 'learning_rate': 1.1632478632478635e-05, 'mean_token_accuracy': 0.717531430721283, 'epoch': 1.26}
{'loss': 0.8198, 'grad_norm': 2.6809091567993164, 'learning_rate': 1.1547008547008546e-05, 'mean_token_accuracy': 0.7204612016677856, 'epoch': 1.27}
{'loss': 0.8606, 'grad_norm': 3.150057554244995, 'learning_rate': 1.1461538461538462e-05, 'mean_token_accuracy': 0.7171145379543304, 'epoch': 1.28}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 51%|█████▏    | 1200/2340 [12:53<11:22,  1.67it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.8893, 'grad_norm': 3.6605641841888428, 'learning_rate': 1.1376068376068377e-05, 'mean_token_accuracy': 0.704582417011261, 'epoch': 1.29}
{'loss': 0.8594, 'grad_norm': 2.9115259647369385, 'learning_rate': 1.1290598290598291e-05, 'mean_token_accuracy': 0.70712331533432, 'epoch': 1.31}
{'loss': 0.7353, 'grad_norm': 2.529088020324707, 'learning_rate': 1.1205128205128205e-05, 'mean_token_accuracy': 0.7296851336956024, 'epoch': 1.32}
{'loss': 0.8014, 'grad_norm': 3.0165882110595703, 'learning_rate': 1.1119658119658122e-05, 'mean_token_accuracy': 0.7300707042217255, 'epoch': 1.33}
{'loss': 0.8298, 'grad_norm': 3.1835250854492188, 'learning_rate': 1.1034188034188036e-05, 'mean_token_accuracy': 0.7193832039833069, 'epoch': 1.35}
{'loss': 0.8534, 'grad_norm': 3.5341975688934326, 'learning_rate': 1.094871794871795e-05, 'mean_token_accuracy': 0.7092455804347992, 'epoch': 1.36}
{'loss': 0.8383, 'grad_norm': 3.598860502243042, 'learning_rate': 1.0863247863247863e-05, 'mean_token_accuracy': 0.713183605670929, 'epoch': 1.37}
{'loss': 0.9161, 'grad_norm': 3.325113534927368, 'learning_rate': 1.0777777777777778e-05, 'mean_token_accuracy': 0.7079934179782867, 'epoch': 1.38}
{'loss': 0.8843, 'grad_norm': 3.0991950035095215, 'learning_rate': 1.0692307692307694e-05, 'mean_token_accuracy': 0.7096910059452057, 'epoch': 1.4}
{'loss': 0.7821, 'grad_norm': 2.782219886779785, 'learning_rate': 1.0606837606837608e-05, 'mean_token_accuracy': 0.7247312128543854, 'epoch': 1.41}
{'loss': 0.7967, 'grad_norm': 3.128683090209961, 'learning_rate': 1.0521367521367523e-05, 'mean_token_accuracy': 0.7193222582340241, 'epoch': 1.42}
{'loss': 0.8541, 'grad_norm': 2.5387766361236572, 'learning_rate': 1.0435897435897437e-05, 'mean_token_accuracy': 0.7095591008663178, 'epoch': 1.44}
{'loss': 0.8061, 'grad_norm': 2.5563557147979736, 'learning_rate': 1.0350427350427353e-05, 'mean_token_accuracy': 0.7181306064128876, 'epoch': 1.45}
{'loss': 0.8613, 'grad_norm': 3.0809757709503174, 'learning_rate': 1.0264957264957264e-05, 'mean_token_accuracy': 0.7125733971595765, 'epoch': 1.46}
{'loss': 0.9043, 'grad_norm': 4.999630928039551, 'learning_rate': 1.017948717948718e-05, 'mean_token_accuracy': 0.7101824700832366, 'epoch': 1.47}
{'loss': 0.7427, 'grad_norm': 3.711547613143921, 'learning_rate': 1.0094017094017095e-05, 'mean_token_accuracy': 0.7299608826637268, 'epoch': 1.49}
{'loss': 0.772, 'grad_norm': 3.42690110206604, 'learning_rate': 1.0008547008547009e-05, 'mean_token_accuracy': 0.7210361182689666, 'epoch': 1.5}
{'loss': 0.719, 'grad_norm': 4.6072893142700195, 'learning_rate': 9.923076923076923e-06, 'mean_token_accuracy': 0.7373267829418182, 'epoch': 1.51}
{'loss': 0.8789, 'grad_norm': 3.0381968021392822, 'learning_rate': 9.837606837606838e-06, 'mean_token_accuracy': 0.7035141348838806, 'epoch': 1.53}
{'loss': 0.8581, 'grad_norm': 2.892200469970703, 'learning_rate': 9.752136752136752e-06, 'mean_token_accuracy': 0.7195040285587311, 'epoch': 1.54}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 60%|█████▉    | 1400/2340 [15:03<09:05,  1.72it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.7746, 'grad_norm': 3.8234503269195557, 'learning_rate': 9.666666666666667e-06, 'mean_token_accuracy': 0.7229660093784332, 'epoch': 1.55}
{'loss': 0.8111, 'grad_norm': 2.7592837810516357, 'learning_rate': 9.581196581196583e-06, 'mean_token_accuracy': 0.7268537282943726, 'epoch': 1.56}
{'loss': 0.8028, 'grad_norm': 2.8822543621063232, 'learning_rate': 9.495726495726496e-06, 'mean_token_accuracy': 0.7224106192588806, 'epoch': 1.58}
{'loss': 0.7531, 'grad_norm': 5.242946624755859, 'learning_rate': 9.410256410256412e-06, 'mean_token_accuracy': 0.7383565425872802, 'epoch': 1.59}
{'loss': 0.8427, 'grad_norm': 3.6850533485412598, 'learning_rate': 9.324786324786326e-06, 'mean_token_accuracy': 0.7150894463062286, 'epoch': 1.6}
{'loss': 0.8563, 'grad_norm': 3.2660305500030518, 'learning_rate': 9.23931623931624e-06, 'mean_token_accuracy': 0.7143771708011627, 'epoch': 1.62}
{'loss': 0.8835, 'grad_norm': 3.256167411804199, 'learning_rate': 9.153846153846155e-06, 'mean_token_accuracy': 0.7079674959182739, 'epoch': 1.63}
{'loss': 0.8494, 'grad_norm': 3.21215558052063, 'learning_rate': 9.06837606837607e-06, 'mean_token_accuracy': 0.7133161962032318, 'epoch': 1.64}
{'loss': 0.7912, 'grad_norm': 3.1601550579071045, 'learning_rate': 8.982905982905984e-06, 'mean_token_accuracy': 0.7298286557197571, 'epoch': 1.65}
{'loss': 0.8278, 'grad_norm': 3.243751287460327, 'learning_rate': 8.897435897435898e-06, 'mean_token_accuracy': 0.7165847301483155, 'epoch': 1.67}
{'loss': 0.8328, 'grad_norm': 2.850302219390869, 'learning_rate': 8.811965811965813e-06, 'mean_token_accuracy': 0.7201635003089905, 'epoch': 1.68}
{'loss': 0.833, 'grad_norm': 4.596280574798584, 'learning_rate': 8.726495726495727e-06, 'mean_token_accuracy': 0.7150029420852662, 'epoch': 1.69}
{'loss': 0.7772, 'grad_norm': 2.4004838466644287, 'learning_rate': 8.641025641025641e-06, 'mean_token_accuracy': 0.7250504493713379, 'epoch': 1.71}
{'loss': 0.8224, 'grad_norm': 3.3751296997070312, 'learning_rate': 8.555555555555556e-06, 'mean_token_accuracy': 0.7257565557956696, 'epoch': 1.72}
{'loss': 0.7714, 'grad_norm': 5.300988674163818, 'learning_rate': 8.47008547008547e-06, 'mean_token_accuracy': 0.7295755863189697, 'epoch': 1.73}
{'loss': 0.8301, 'grad_norm': 3.0268900394439697, 'learning_rate': 8.384615384615385e-06, 'mean_token_accuracy': 0.7158114314079285, 'epoch': 1.74}
{'loss': 0.836, 'grad_norm': 2.5407907962799072, 'learning_rate': 8.299145299145301e-06, 'mean_token_accuracy': 0.7206315994262695, 'epoch': 1.76}
{'loss': 0.7697, 'grad_norm': 4.328648567199707, 'learning_rate': 8.213675213675214e-06, 'mean_token_accuracy': 0.7235570251941681, 'epoch': 1.77}
{'loss': 0.7538, 'grad_norm': 3.6259348392486572, 'learning_rate': 8.12820512820513e-06, 'mean_token_accuracy': 0.7274383306503296, 'epoch': 1.78}
{'loss': 0.7426, 'grad_norm': 2.602095127105713, 'learning_rate': 8.042735042735044e-06, 'mean_token_accuracy': 0.7314460635185241, 'epoch': 1.79}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 68%|██████▊   | 1600/2340 [17:13<07:46,  1.59it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.7945, 'grad_norm': 3.905569314956665, 'learning_rate': 7.957264957264957e-06, 'mean_token_accuracy': 0.7303962349891663, 'epoch': 1.81}
{'loss': 0.7613, 'grad_norm': 2.9657182693481445, 'learning_rate': 7.871794871794873e-06, 'mean_token_accuracy': 0.7294155895709992, 'epoch': 1.82}
{'loss': 0.808, 'grad_norm': 4.144552230834961, 'learning_rate': 7.786324786324787e-06, 'mean_token_accuracy': 0.7191184341907502, 'epoch': 1.83}
{'loss': 0.8108, 'grad_norm': 2.942836284637451, 'learning_rate': 7.700854700854702e-06, 'mean_token_accuracy': 0.7235310971736908, 'epoch': 1.85}
{'loss': 0.847, 'grad_norm': 4.8277668952941895, 'learning_rate': 7.615384615384615e-06, 'mean_token_accuracy': 0.7150380790233613, 'epoch': 1.86}
{'loss': 0.7523, 'grad_norm': 4.751704216003418, 'learning_rate': 7.529914529914531e-06, 'mean_token_accuracy': 0.7281494200229645, 'epoch': 1.87}
{'loss': 0.9162, 'grad_norm': 3.4974350929260254, 'learning_rate': 7.444444444444445e-06, 'mean_token_accuracy': 0.7054600238800048, 'epoch': 1.88}
{'loss': 0.8126, 'grad_norm': 3.2015175819396973, 'learning_rate': 7.35897435897436e-06, 'mean_token_accuracy': 0.7248892188072205, 'epoch': 1.9}
{'loss': 0.8095, 'grad_norm': 3.05879807472229, 'learning_rate': 7.273504273504274e-06, 'mean_token_accuracy': 0.723721158504486, 'epoch': 1.91}
{'loss': 0.8451, 'grad_norm': 3.9368014335632324, 'learning_rate': 7.188034188034188e-06, 'mean_token_accuracy': 0.7161628425121307, 'epoch': 1.92}
{'loss': 0.7745, 'grad_norm': 3.4662365913391113, 'learning_rate': 7.102564102564104e-06, 'mean_token_accuracy': 0.7254081070423126, 'epoch': 1.94}
{'loss': 0.7928, 'grad_norm': 2.9368503093719482, 'learning_rate': 7.017094017094017e-06, 'mean_token_accuracy': 0.7269046008586884, 'epoch': 1.95}
{'loss': 0.7242, 'grad_norm': 5.328516483306885, 'learning_rate': 6.931623931623932e-06, 'mean_token_accuracy': 0.7371555626392364, 'epoch': 1.96}
{'loss': 0.8195, 'grad_norm': 7.280916690826416, 'learning_rate': 6.846153846153847e-06, 'mean_token_accuracy': 0.7174718141555786, 'epoch': 1.97}
{'loss': 0.7474, 'grad_norm': 3.7485084533691406, 'learning_rate': 6.760683760683761e-06, 'mean_token_accuracy': 0.7306736588478089, 'epoch': 1.99}
{'loss': 0.7804, 'grad_norm': 3.7508811950683594, 'learning_rate': 6.675213675213676e-06, 'mean_token_accuracy': 0.7246743559837341, 'epoch': 2.0}
{'loss': 0.7992, 'grad_norm': 2.363316059112549, 'learning_rate': 6.58974358974359e-06, 'mean_token_accuracy': 0.7176921963691711, 'epoch': 2.01}
{'loss': 0.7371, 'grad_norm': 2.5829877853393555, 'learning_rate': 6.504273504273505e-06, 'mean_token_accuracy': 0.7331688165664673, 'epoch': 2.03}
{'loss': 0.6754, 'grad_norm': 2.910088062286377, 'learning_rate': 6.41880341880342e-06, 'mean_token_accuracy': 0.7444041252136231, 'epoch': 2.04}
{'loss': 0.7145, 'grad_norm': 2.967461585998535, 'learning_rate': 6.333333333333333e-06, 'mean_token_accuracy': 0.7363340258598328, 'epoch': 2.05}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 77%|███████▋  | 1800/2340 [19:23<05:24,  1.67it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.7841, 'grad_norm': 2.505427837371826, 'learning_rate': 6.247863247863249e-06, 'mean_token_accuracy': 0.7269221723079682, 'epoch': 2.06}
{'loss': 0.8127, 'grad_norm': 3.4460723400115967, 'learning_rate': 6.162393162393163e-06, 'mean_token_accuracy': 0.7279545664787292, 'epoch': 2.08}
{'loss': 0.7978, 'grad_norm': 4.825942516326904, 'learning_rate': 6.076923076923077e-06, 'mean_token_accuracy': 0.7265558540821075, 'epoch': 2.09}
{'loss': 0.8338, 'grad_norm': 4.6500959396362305, 'learning_rate': 5.991452991452992e-06, 'mean_token_accuracy': 0.7174470722675323, 'epoch': 2.1}
{'loss': 0.7703, 'grad_norm': 2.8917288780212402, 'learning_rate': 5.905982905982906e-06, 'mean_token_accuracy': 0.735906571149826, 'epoch': 2.12}
{'loss': 0.7717, 'grad_norm': 2.650062084197998, 'learning_rate': 5.820512820512822e-06, 'mean_token_accuracy': 0.7297449886798859, 'epoch': 2.13}
{'loss': 0.7387, 'grad_norm': 2.875617027282715, 'learning_rate': 5.735042735042735e-06, 'mean_token_accuracy': 0.7342156171798706, 'epoch': 2.14}
{'loss': 0.7293, 'grad_norm': 3.188629627227783, 'learning_rate': 5.64957264957265e-06, 'mean_token_accuracy': 0.7330127477645874, 'epoch': 2.15}
{'loss': 0.789, 'grad_norm': 5.066365718841553, 'learning_rate': 5.564102564102565e-06, 'mean_token_accuracy': 0.7296754717826843, 'epoch': 2.17}
{'loss': 0.6917, 'grad_norm': 5.640138626098633, 'learning_rate': 5.478632478632479e-06, 'mean_token_accuracy': 0.7487204790115356, 'epoch': 2.18}
{'loss': 0.7315, 'grad_norm': 4.525162696838379, 'learning_rate': 5.393162393162394e-06, 'mean_token_accuracy': 0.7340647578239441, 'epoch': 2.19}
{'loss': 0.9006, 'grad_norm': 4.154417037963867, 'learning_rate': 5.307692307692308e-06, 'mean_token_accuracy': 0.7115602016448974, 'epoch': 2.21}
{'loss': 0.7723, 'grad_norm': 4.755018711090088, 'learning_rate': 5.2222222222222226e-06, 'mean_token_accuracy': 0.7306943893432617, 'epoch': 2.22}
{'loss': 0.7841, 'grad_norm': 3.3782317638397217, 'learning_rate': 5.136752136752137e-06, 'mean_token_accuracy': 0.7290574133396148, 'epoch': 2.23}
{'loss': 0.8538, 'grad_norm': 2.2817022800445557, 'learning_rate': 5.051282051282051e-06, 'mean_token_accuracy': 0.7168469130992889, 'epoch': 2.24}
{'loss': 0.7492, 'grad_norm': 3.4659793376922607, 'learning_rate': 4.965811965811967e-06, 'mean_token_accuracy': 0.729432362318039, 'epoch': 2.26}
{'loss': 0.7655, 'grad_norm': 4.453211307525635, 'learning_rate': 4.88034188034188e-06, 'mean_token_accuracy': 0.7337649762630463, 'epoch': 2.27}
{'loss': 0.7816, 'grad_norm': 3.461030960083008, 'learning_rate': 4.7948717948717955e-06, 'mean_token_accuracy': 0.7263291358947754, 'epoch': 2.28}
{'loss': 0.7649, 'grad_norm': 3.7796854972839355, 'learning_rate': 4.70940170940171e-06, 'mean_token_accuracy': 0.7229597508907318, 'epoch': 2.29}
{'loss': 0.8012, 'grad_norm': 3.0741629600524902, 'learning_rate': 4.623931623931624e-06, 'mean_token_accuracy': 0.7295617580413818, 'epoch': 2.31}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 85%|████████▌ | 2000/2340 [21:32<03:23,  1.67it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.772, 'grad_norm': 3.100736379623413, 'learning_rate': 4.538461538461539e-06, 'mean_token_accuracy': 0.7275085687637329, 'epoch': 2.32}
{'loss': 0.735, 'grad_norm': 4.08340311050415, 'learning_rate': 4.452991452991453e-06, 'mean_token_accuracy': 0.739150196313858, 'epoch': 2.33}
{'loss': 0.7356, 'grad_norm': 3.2357380390167236, 'learning_rate': 4.367521367521368e-06, 'mean_token_accuracy': 0.7337556064128876, 'epoch': 2.35}
{'loss': 0.8, 'grad_norm': 2.8095552921295166, 'learning_rate': 4.282051282051282e-06, 'mean_token_accuracy': 0.7272291779518127, 'epoch': 2.36}
{'loss': 0.8263, 'grad_norm': 3.038975715637207, 'learning_rate': 4.196581196581197e-06, 'mean_token_accuracy': 0.7234580516815186, 'epoch': 2.37}
{'loss': 0.7414, 'grad_norm': 3.567466974258423, 'learning_rate': 4.111111111111111e-06, 'mean_token_accuracy': 0.733736103773117, 'epoch': 2.38}
{'loss': 0.7014, 'grad_norm': 4.04085111618042, 'learning_rate': 4.025641025641026e-06, 'mean_token_accuracy': 0.7352964341640472, 'epoch': 2.4}
{'loss': 0.7366, 'grad_norm': 3.2027642726898193, 'learning_rate': 3.940170940170941e-06, 'mean_token_accuracy': 0.7377107322216034, 'epoch': 2.41}
{'loss': 0.6753, 'grad_norm': 3.932229518890381, 'learning_rate': 3.854700854700855e-06, 'mean_token_accuracy': 0.7517999768257141, 'epoch': 2.42}
{'loss': 0.7475, 'grad_norm': 4.266290187835693, 'learning_rate': 3.7692307692307694e-06, 'mean_token_accuracy': 0.7306414425373078, 'epoch': 2.44}
{'loss': 0.7182, 'grad_norm': 2.977372407913208, 'learning_rate': 3.6837606837606843e-06, 'mean_token_accuracy': 0.7344161689281463, 'epoch': 2.45}
{'loss': 0.7315, 'grad_norm': 5.1333231925964355, 'learning_rate': 3.5982905982905987e-06, 'mean_token_accuracy': 0.7342900037765503, 'epoch': 2.46}
{'loss': 0.8328, 'grad_norm': 4.265655040740967, 'learning_rate': 3.5128205128205127e-06, 'mean_token_accuracy': 0.7208690583705902, 'epoch': 2.47}
{'loss': 0.773, 'grad_norm': 2.9891626834869385, 'learning_rate': 3.4273504273504275e-06, 'mean_token_accuracy': 0.7348901212215424, 'epoch': 2.49}
{'loss': 0.6282, 'grad_norm': 4.064119338989258, 'learning_rate': 3.341880341880342e-06, 'mean_token_accuracy': 0.7522515177726745, 'epoch': 2.5}
{'loss': 0.8133, 'grad_norm': 5.201380729675293, 'learning_rate': 3.256410256410257e-06, 'mean_token_accuracy': 0.7161225020885468, 'epoch': 2.51}
{'loss': 0.764, 'grad_norm': 3.8802762031555176, 'learning_rate': 3.1709401709401712e-06, 'mean_token_accuracy': 0.727339506149292, 'epoch': 2.53}
{'loss': 0.6674, 'grad_norm': 2.8076062202453613, 'learning_rate': 3.0854700854700857e-06, 'mean_token_accuracy': 0.7507023274898529, 'epoch': 2.54}
{'loss': 0.7473, 'grad_norm': 4.463089942932129, 'learning_rate': 3e-06, 'mean_token_accuracy': 0.7303563117980957, 'epoch': 2.55}
{'loss': 0.7542, 'grad_norm': 3.636754035949707, 'learning_rate': 2.914529914529915e-06, 'mean_token_accuracy': 0.7357542216777802, 'epoch': 2.56}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 94%|█████████▍| 2200/2340 [23:41<01:24,  1.66it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.6937, 'grad_norm': 2.691654682159424, 'learning_rate': 2.8290598290598293e-06, 'mean_token_accuracy': 0.7446582436561584, 'epoch': 2.58}
{'loss': 0.826, 'grad_norm': 3.0182793140411377, 'learning_rate': 2.743589743589744e-06, 'mean_token_accuracy': 0.7193428039550781, 'epoch': 2.59}
{'loss': 0.6024, 'grad_norm': 3.9659125804901123, 'learning_rate': 2.658119658119658e-06, 'mean_token_accuracy': 0.7571073532104492, 'epoch': 2.6}
{'loss': 0.7237, 'grad_norm': 3.7031238079071045, 'learning_rate': 2.5726495726495726e-06, 'mean_token_accuracy': 0.7355901718139648, 'epoch': 2.62}
{'loss': 0.7416, 'grad_norm': 3.010385751724243, 'learning_rate': 2.4871794871794875e-06, 'mean_token_accuracy': 0.7368778944015503, 'epoch': 2.63}
{'loss': 0.8432, 'grad_norm': 3.8033926486968994, 'learning_rate': 2.401709401709402e-06, 'mean_token_accuracy': 0.7197896540164948, 'epoch': 2.64}
{'loss': 0.704, 'grad_norm': 4.0396623611450195, 'learning_rate': 2.3162393162393167e-06, 'mean_token_accuracy': 0.7410533666610718, 'epoch': 2.65}
{'loss': 0.784, 'grad_norm': 4.042724609375, 'learning_rate': 2.230769230769231e-06, 'mean_token_accuracy': 0.730853009223938, 'epoch': 2.67}
{'loss': 0.7325, 'grad_norm': 3.4749691486358643, 'learning_rate': 2.145299145299145e-06, 'mean_token_accuracy': 0.7313816964626312, 'epoch': 2.68}
{'loss': 0.7967, 'grad_norm': 3.836723566055298, 'learning_rate': 2.05982905982906e-06, 'mean_token_accuracy': 0.7231679916381836, 'epoch': 2.69}
{'loss': 0.6686, 'grad_norm': 2.423088312149048, 'learning_rate': 1.9743589743589744e-06, 'mean_token_accuracy': 0.7470041692256928, 'epoch': 2.71}
{'loss': 0.7222, 'grad_norm': 3.733491897583008, 'learning_rate': 1.888888888888889e-06, 'mean_token_accuracy': 0.7357858300209046, 'epoch': 2.72}
{'loss': 0.7942, 'grad_norm': 4.013747692108154, 'learning_rate': 1.8034188034188035e-06, 'mean_token_accuracy': 0.7234603106975556, 'epoch': 2.73}
{'loss': 0.7379, 'grad_norm': 3.1815671920776367, 'learning_rate': 1.717948717948718e-06, 'mean_token_accuracy': 0.7302366018295288, 'epoch': 2.74}
{'loss': 0.7746, 'grad_norm': 4.490256309509277, 'learning_rate': 1.6324786324786327e-06, 'mean_token_accuracy': 0.7286482751369476, 'epoch': 2.76}
{'loss': 0.628, 'grad_norm': 2.9955592155456543, 'learning_rate': 1.5470085470085471e-06, 'mean_token_accuracy': 0.7592428386211395, 'epoch': 2.77}
{'loss': 0.7304, 'grad_norm': 3.081841468811035, 'learning_rate': 1.4615384615384618e-06, 'mean_token_accuracy': 0.7399732887744903, 'epoch': 2.78}
{'loss': 0.7413, 'grad_norm': 3.461516857147217, 'learning_rate': 1.3760683760683762e-06, 'mean_token_accuracy': 0.7362466871738433, 'epoch': 2.79}
{'loss': 0.6947, 'grad_norm': 3.3619449138641357, 'learning_rate': 1.2905982905982908e-06, 'mean_token_accuracy': 0.741933137178421, 'epoch': 2.81}
{'loss': 0.7597, 'grad_norm': 2.9743800163269043, 'learning_rate': 1.2051282051282053e-06, 'mean_token_accuracy': 0.7358887732028961, 'epoch': 2.82}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
100%|██████████| 2340/2340 [25:14<00:00,  1.85it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.7224, 'grad_norm': 2.669663429260254, 'learning_rate': 1.1196581196581199e-06, 'mean_token_accuracy': 0.7370552659034729, 'epoch': 2.83}
{'loss': 0.7309, 'grad_norm': 4.073488712310791, 'learning_rate': 1.034188034188034e-06, 'mean_token_accuracy': 0.7322533965110779, 'epoch': 2.85}
{'loss': 0.7589, 'grad_norm': 3.3724069595336914, 'learning_rate': 9.487179487179487e-07, 'mean_token_accuracy': 0.731398469209671, 'epoch': 2.86}
{'loss': 0.8368, 'grad_norm': 2.4862372875213623, 'learning_rate': 8.632478632478633e-07, 'mean_token_accuracy': 0.72232586145401, 'epoch': 2.87}
{'loss': 0.8334, 'grad_norm': 3.2209324836730957, 'learning_rate': 7.777777777777779e-07, 'mean_token_accuracy': 0.7261330127716065, 'epoch': 2.88}
{'loss': 0.7023, 'grad_norm': 3.192081928253174, 'learning_rate': 6.923076923076924e-07, 'mean_token_accuracy': 0.7361744344234467, 'epoch': 2.9}
{'loss': 0.7372, 'grad_norm': 3.2012197971343994, 'learning_rate': 6.068376068376068e-07, 'mean_token_accuracy': 0.7412699222564697, 'epoch': 2.91}
{'loss': 0.7876, 'grad_norm': 3.3146350383758545, 'learning_rate': 5.213675213675215e-07, 'mean_token_accuracy': 0.7278450906276703, 'epoch': 2.92}
{'loss': 0.822, 'grad_norm': 2.7999589443206787, 'learning_rate': 4.358974358974359e-07, 'mean_token_accuracy': 0.7275398015975952, 'epoch': 2.94}
{'loss': 0.736, 'grad_norm': 2.9138760566711426, 'learning_rate': 3.504273504273505e-07, 'mean_token_accuracy': 0.7411060869693756, 'epoch': 2.95}
{'loss': 0.7918, 'grad_norm': 3.4646716117858887, 'learning_rate': 2.6495726495726495e-07, 'mean_token_accuracy': 0.7267087578773499, 'epoch': 2.96}
{'loss': 0.7974, 'grad_norm': 3.049264669418335, 'learning_rate': 1.7948717948717948e-07, 'mean_token_accuracy': 0.7246242344379425, 'epoch': 2.97}
{'loss': 0.7212, 'grad_norm': 2.900557279586792, 'learning_rate': 9.401709401709402e-08, 'mean_token_accuracy': 0.7367893874645233, 'epoch': 2.99}
{'loss': 0.837, 'grad_norm': 3.0024523735046387, 'learning_rate': 8.547008547008548e-09, 'mean_token_accuracy': 0.719939649105072, 'epoch': 3.0}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
100%|██████████| 2340/2340 [25:24<00:00,  1.53it/s]
{'train_runtime': 1526.8905, 'train_samples_per_second': 12.254, 'train_steps_per_second': 1.533, 'train_loss': 0.8983059858664488, 'epoch': 3.0}
/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
