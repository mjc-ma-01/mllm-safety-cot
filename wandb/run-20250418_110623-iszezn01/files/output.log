  0%|          | 0/492 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
 25%|██▍       | 122/492 [03:13<09:45,  1.58s/it]Traceback (most recent call last):
{'loss': 2.0991, 'grad_norm': 24.619670867919922, 'learning_rate': 1.9634146341463414e-05, 'mean_token_accuracy': 0.5846113786101341, 'epoch': 0.04}
{'loss': 1.384, 'grad_norm': 18.3682804107666, 'learning_rate': 1.9227642276422765e-05, 'mean_token_accuracy': 0.6478867888450622, 'epoch': 0.08}
{'loss': 1.3616, 'grad_norm': 16.738304138183594, 'learning_rate': 1.8821138211382116e-05, 'mean_token_accuracy': 0.6494215607643128, 'epoch': 0.12}
{'loss': 1.2571, 'grad_norm': 16.85999870300293, 'learning_rate': 1.8414634146341467e-05, 'mean_token_accuracy': 0.6717030167579651, 'epoch': 0.16}
{'loss': 1.3077, 'grad_norm': 21.515369415283203, 'learning_rate': 1.8008130081300814e-05, 'mean_token_accuracy': 0.670228898525238, 'epoch': 0.2}
{'loss': 1.2947, 'grad_norm': 14.572321891784668, 'learning_rate': 1.7601626016260165e-05, 'mean_token_accuracy': 0.673559719324112, 'epoch': 0.24}
{'loss': 1.3076, 'grad_norm': 35.90407180786133, 'learning_rate': 1.7195121951219512e-05, 'mean_token_accuracy': 0.6780390799045563, 'epoch': 0.28}
{'loss': 1.2083, 'grad_norm': 15.796117782592773, 'learning_rate': 1.6788617886178863e-05, 'mean_token_accuracy': 0.6770963668823242, 'epoch': 0.33}
{'loss': 1.1811, 'grad_norm': 15.895180702209473, 'learning_rate': 1.6382113821138214e-05, 'mean_token_accuracy': 0.7003047883510589, 'epoch': 0.37}
{'loss': 1.1356, 'grad_norm': 17.607959747314453, 'learning_rate': 1.597560975609756e-05, 'mean_token_accuracy': 0.7184771656990051, 'epoch': 0.41}
{'loss': 1.1991, 'grad_norm': 14.758766174316406, 'learning_rate': 1.5569105691056912e-05, 'mean_token_accuracy': 0.6930723011493682, 'epoch': 0.45}
{'loss': 1.2184, 'grad_norm': 17.78092384338379, 'learning_rate': 1.5162601626016263e-05, 'mean_token_accuracy': 0.6920624494552612, 'epoch': 0.49}
  File "/mnt/petrelfs/majiachen/project/mllm-safety-cot/src/sft_vlm_cot_.py", line 274, in <module>
    trainer.train()
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
    return inner_training_loop(
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 3782, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/accelerate/accelerator.py", line 2238, in backward
    self.deepspeed_engine_wrapped.backward(loss, **kwargs)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 261, in backward
    self.engine.backward(loss, **kwargs)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2053, in backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 2062, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mnt/petrelfs/majiachen/project/mllm-safety-cot/src/sft_vlm_cot_.py", line 274, in <module>
[rank0]:     trainer.train()
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
[rank0]:     return inner_training_loop(
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/transformers/trainer.py", line 3782, in training_step
[rank0]:     self.accelerator.backward(loss, **kwargs)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/accelerate/accelerator.py", line 2238, in backward
[rank0]:     self.deepspeed_engine_wrapped.backward(loss, **kwargs)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/accelerate/utils/deepspeed.py", line 261, in backward
[rank0]:     self.engine.backward(loss, **kwargs)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 2053, in backward
[rank0]:     self.optimizer.backward(loss, retain_graph=retain_graph)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py", line 2062, in backward
[rank0]:     self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
[rank0]:     scaled_loss.backward(retain_graph=retain_graph)
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]: KeyboardInterrupt
