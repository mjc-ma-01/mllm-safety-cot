  0%|          | 0/1665 [00:00<?, ?it/s]It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.
 12%|█▏        | 200/1665 [02:04<14:35,  1.67it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 2.7774, 'grad_norm': 8.875479698181152, 'learning_rate': 1.9891891891891894e-05, 'mean_token_accuracy': 0.5183500617742538, 'epoch': 0.02}
{'loss': 2.0335, 'grad_norm': 5.542367935180664, 'learning_rate': 1.9771771771771773e-05, 'mean_token_accuracy': 0.5498408615589142, 'epoch': 0.04}
{'loss': 1.8637, 'grad_norm': 2.7460644245147705, 'learning_rate': 1.965165165165165e-05, 'mean_token_accuracy': 0.5780674934387207, 'epoch': 0.05}
{'loss': 1.6753, 'grad_norm': 4.430747032165527, 'learning_rate': 1.9531531531531534e-05, 'mean_token_accuracy': 0.5942008376121521, 'epoch': 0.07}
{'loss': 1.5178, 'grad_norm': 3.260468006134033, 'learning_rate': 1.9411411411411413e-05, 'mean_token_accuracy': 0.6214373290538788, 'epoch': 0.09}
{'loss': 1.5326, 'grad_norm': 2.331293821334839, 'learning_rate': 1.929129129129129e-05, 'mean_token_accuracy': 0.6184325039386749, 'epoch': 0.11}
{'loss': 1.471, 'grad_norm': 2.539031744003296, 'learning_rate': 1.9171171171171174e-05, 'mean_token_accuracy': 0.6253920793533325, 'epoch': 0.13}
{'loss': 1.4608, 'grad_norm': 2.4491004943847656, 'learning_rate': 1.9051051051051052e-05, 'mean_token_accuracy': 0.6236123740673065, 'epoch': 0.14}
{'loss': 1.4246, 'grad_norm': 2.837712287902832, 'learning_rate': 1.8930930930930935e-05, 'mean_token_accuracy': 0.6238762378692627, 'epoch': 0.16}
{'loss': 1.4119, 'grad_norm': 3.2168567180633545, 'learning_rate': 1.8810810810810813e-05, 'mean_token_accuracy': 0.6319204151630402, 'epoch': 0.18}
{'loss': 1.3676, 'grad_norm': 2.385040044784546, 'learning_rate': 1.8690690690690692e-05, 'mean_token_accuracy': 0.6376289963722229, 'epoch': 0.2}
{'loss': 1.305, 'grad_norm': 2.1085360050201416, 'learning_rate': 1.857057057057057e-05, 'mean_token_accuracy': 0.6408198416233063, 'epoch': 0.22}
{'loss': 1.3758, 'grad_norm': 2.8239593505859375, 'learning_rate': 1.8450450450450453e-05, 'mean_token_accuracy': 0.6343043327331543, 'epoch': 0.23}
{'loss': 1.2596, 'grad_norm': 8.249881744384766, 'learning_rate': 1.8330330330330332e-05, 'mean_token_accuracy': 0.6445227026939392, 'epoch': 0.25}
{'loss': 1.2715, 'grad_norm': 3.690256357192993, 'learning_rate': 1.821021021021021e-05, 'mean_token_accuracy': 0.6468004643917084, 'epoch': 0.27}
{'loss': 1.2287, 'grad_norm': 4.084364891052246, 'learning_rate': 1.809009009009009e-05, 'mean_token_accuracy': 0.6501006543636322, 'epoch': 0.29}
{'loss': 1.2528, 'grad_norm': 3.334423065185547, 'learning_rate': 1.7969969969969972e-05, 'mean_token_accuracy': 0.654449212551117, 'epoch': 0.31}
{'loss': 1.2246, 'grad_norm': 2.8422648906707764, 'learning_rate': 1.784984984984985e-05, 'mean_token_accuracy': 0.6583237588405609, 'epoch': 0.32}
{'loss': 1.2191, 'grad_norm': 3.6017813682556152, 'learning_rate': 1.7729729729729733e-05, 'mean_token_accuracy': 0.6510683059692383, 'epoch': 0.34}
{'loss': 1.2029, 'grad_norm': 3.5089774131774902, 'learning_rate': 1.760960960960961e-05, 'mean_token_accuracy': 0.6562345802783967, 'epoch': 0.36}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 24%|██▍       | 400/1665 [04:14<12:36,  1.67it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 1.202, 'grad_norm': 3.491541862487793, 'learning_rate': 1.748948948948949e-05, 'mean_token_accuracy': 0.657934021949768, 'epoch': 0.38}
{'loss': 1.1685, 'grad_norm': 3.156630754470825, 'learning_rate': 1.7369369369369373e-05, 'mean_token_accuracy': 0.6582462251186371, 'epoch': 0.4}
{'loss': 1.0841, 'grad_norm': 14.021878242492676, 'learning_rate': 1.724924924924925e-05, 'mean_token_accuracy': 0.6690397083759307, 'epoch': 0.41}
{'loss': 1.1129, 'grad_norm': 4.647951126098633, 'learning_rate': 1.712912912912913e-05, 'mean_token_accuracy': 0.6687228560447693, 'epoch': 0.43}
{'loss': 1.0986, 'grad_norm': 4.664346694946289, 'learning_rate': 1.700900900900901e-05, 'mean_token_accuracy': 0.6792417049407959, 'epoch': 0.45}
{'loss': 1.0849, 'grad_norm': 4.266687393188477, 'learning_rate': 1.688888888888889e-05, 'mean_token_accuracy': 0.6737967669963837, 'epoch': 0.47}
{'loss': 1.0639, 'grad_norm': 4.341700553894043, 'learning_rate': 1.676876876876877e-05, 'mean_token_accuracy': 0.6728391706943512, 'epoch': 0.49}
{'loss': 1.0939, 'grad_norm': 3.578791856765747, 'learning_rate': 1.6648648648648652e-05, 'mean_token_accuracy': 0.6704114437103271, 'epoch': 0.5}
{'loss': 1.0653, 'grad_norm': 5.115698337554932, 'learning_rate': 1.6528528528528528e-05, 'mean_token_accuracy': 0.6732677280902862, 'epoch': 0.52}
{'loss': 1.0572, 'grad_norm': 7.070250034332275, 'learning_rate': 1.640840840840841e-05, 'mean_token_accuracy': 0.675163847208023, 'epoch': 0.54}
{'loss': 1.0335, 'grad_norm': 3.4754154682159424, 'learning_rate': 1.628828828828829e-05, 'mean_token_accuracy': 0.6839612662792206, 'epoch': 0.56}
{'loss': 0.9645, 'grad_norm': 5.265125274658203, 'learning_rate': 1.616816816816817e-05, 'mean_token_accuracy': 0.6943669438362121, 'epoch': 0.58}
{'loss': 0.9875, 'grad_norm': 5.903595924377441, 'learning_rate': 1.604804804804805e-05, 'mean_token_accuracy': 0.6826698243618011, 'epoch': 0.59}
{'loss': 0.9205, 'grad_norm': 2.618748188018799, 'learning_rate': 1.592792792792793e-05, 'mean_token_accuracy': 0.6950042903423309, 'epoch': 0.61}
{'loss': 0.9333, 'grad_norm': 5.926886558532715, 'learning_rate': 1.5807807807807807e-05, 'mean_token_accuracy': 0.6855976700782775, 'epoch': 0.63}
{'loss': 0.9419, 'grad_norm': 6.865347862243652, 'learning_rate': 1.568768768768769e-05, 'mean_token_accuracy': 0.689877039194107, 'epoch': 0.65}
{'loss': 0.8856, 'grad_norm': 6.577505111694336, 'learning_rate': 1.556756756756757e-05, 'mean_token_accuracy': 0.7020905256271363, 'epoch': 0.67}
{'loss': 0.92, 'grad_norm': 6.027514457702637, 'learning_rate': 1.5447447447447447e-05, 'mean_token_accuracy': 0.6935645163059234, 'epoch': 0.68}
{'loss': 0.9389, 'grad_norm': 5.03812837600708, 'learning_rate': 1.532732732732733e-05, 'mean_token_accuracy': 0.7008889973163605, 'epoch': 0.7}
{'loss': 0.9431, 'grad_norm': 6.859551429748535, 'learning_rate': 1.5207207207207208e-05, 'mean_token_accuracy': 0.6954541146755219, 'epoch': 0.72}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 36%|███▌      | 600/1665 [06:24<10:25,  1.70it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.8578, 'grad_norm': 6.067948341369629, 'learning_rate': 1.5087087087087089e-05, 'mean_token_accuracy': 0.712875247001648, 'epoch': 0.74}
{'loss': 0.8383, 'grad_norm': 4.235828876495361, 'learning_rate': 1.496696696696697e-05, 'mean_token_accuracy': 0.711831796169281, 'epoch': 0.76}
{'loss': 0.8857, 'grad_norm': 5.548603534698486, 'learning_rate': 1.4846846846846848e-05, 'mean_token_accuracy': 0.7060521364212036, 'epoch': 0.77}
{'loss': 0.9291, 'grad_norm': 5.348703861236572, 'learning_rate': 1.4726726726726729e-05, 'mean_token_accuracy': 0.6901898145675659, 'epoch': 0.79}
{'loss': 0.8418, 'grad_norm': 4.558390140533447, 'learning_rate': 1.4606606606606607e-05, 'mean_token_accuracy': 0.7072295069694519, 'epoch': 0.81}
{'loss': 0.7987, 'grad_norm': 12.024319648742676, 'learning_rate': 1.4486486486486488e-05, 'mean_token_accuracy': 0.7164549767971039, 'epoch': 0.83}
{'loss': 0.9393, 'grad_norm': 4.343721389770508, 'learning_rate': 1.4366366366366367e-05, 'mean_token_accuracy': 0.691975611448288, 'epoch': 0.85}
{'loss': 0.7976, 'grad_norm': 8.03029727935791, 'learning_rate': 1.4246246246246247e-05, 'mean_token_accuracy': 0.7131388247013092, 'epoch': 0.86}
{'loss': 0.9062, 'grad_norm': 7.085195064544678, 'learning_rate': 1.4126126126126128e-05, 'mean_token_accuracy': 0.6986039757728577, 'epoch': 0.88}
{'loss': 0.853, 'grad_norm': 3.9100334644317627, 'learning_rate': 1.4006006006006008e-05, 'mean_token_accuracy': 0.7104581832885742, 'epoch': 0.9}
{'loss': 0.7802, 'grad_norm': 4.312325954437256, 'learning_rate': 1.3885885885885889e-05, 'mean_token_accuracy': 0.7174346327781678, 'epoch': 0.92}
{'loss': 0.8353, 'grad_norm': 8.934274673461914, 'learning_rate': 1.3765765765765766e-05, 'mean_token_accuracy': 0.7095889627933503, 'epoch': 0.94}
{'loss': 0.9136, 'grad_norm': 3.3044419288635254, 'learning_rate': 1.3645645645645646e-05, 'mean_token_accuracy': 0.7039228737354278, 'epoch': 0.95}
{'loss': 0.8267, 'grad_norm': 3.9636123180389404, 'learning_rate': 1.3525525525525527e-05, 'mean_token_accuracy': 0.7125015258789062, 'epoch': 0.97}
{'loss': 0.7834, 'grad_norm': 4.952873706817627, 'learning_rate': 1.3405405405405407e-05, 'mean_token_accuracy': 0.7220010697841645, 'epoch': 0.99}
{'loss': 0.8781, 'grad_norm': 3.500183343887329, 'learning_rate': 1.3285285285285286e-05, 'mean_token_accuracy': 0.7029640138149261, 'epoch': 1.01}
{'loss': 0.828, 'grad_norm': 2.919921636581421, 'learning_rate': 1.3165165165165165e-05, 'mean_token_accuracy': 0.7132847964763641, 'epoch': 1.03}
{'loss': 0.9585, 'grad_norm': 4.037082195281982, 'learning_rate': 1.3045045045045045e-05, 'mean_token_accuracy': 0.6990204215049743, 'epoch': 1.05}
{'loss': 0.8478, 'grad_norm': 4.3721022605896, 'learning_rate': 1.2924924924924926e-05, 'mean_token_accuracy': 0.7063701272010803, 'epoch': 1.06}
{'loss': 0.8093, 'grad_norm': 4.756322860717773, 'learning_rate': 1.2804804804804807e-05, 'mean_token_accuracy': 0.7102192044258118, 'epoch': 1.08}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 48%|████▊     | 800/1665 [08:33<08:27,  1.70it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.7404, 'grad_norm': 4.0127692222595215, 'learning_rate': 1.2684684684684685e-05, 'mean_token_accuracy': 0.724640953540802, 'epoch': 1.1}
{'loss': 0.8052, 'grad_norm': 2.938871145248413, 'learning_rate': 1.2564564564564566e-05, 'mean_token_accuracy': 0.7149196028709411, 'epoch': 1.12}
{'loss': 0.8208, 'grad_norm': 3.10003662109375, 'learning_rate': 1.2444444444444446e-05, 'mean_token_accuracy': 0.7151340663433075, 'epoch': 1.14}
{'loss': 0.8367, 'grad_norm': 3.9516234397888184, 'learning_rate': 1.2324324324324327e-05, 'mean_token_accuracy': 0.7145541608333588, 'epoch': 1.15}
{'loss': 0.8108, 'grad_norm': 5.168276309967041, 'learning_rate': 1.2204204204204204e-05, 'mean_token_accuracy': 0.7127312302589417, 'epoch': 1.17}
{'loss': 0.8039, 'grad_norm': 6.61160135269165, 'learning_rate': 1.2084084084084084e-05, 'mean_token_accuracy': 0.7105039834976197, 'epoch': 1.19}
{'loss': 0.8163, 'grad_norm': 3.174561023712158, 'learning_rate': 1.1963963963963965e-05, 'mean_token_accuracy': 0.7203398585319519, 'epoch': 1.21}
{'loss': 0.7532, 'grad_norm': 6.105758190155029, 'learning_rate': 1.1843843843843845e-05, 'mean_token_accuracy': 0.7301886260509491, 'epoch': 1.23}
{'loss': 0.8456, 'grad_norm': 4.531009197235107, 'learning_rate': 1.1723723723723726e-05, 'mean_token_accuracy': 0.7102959096431732, 'epoch': 1.24}
{'loss': 0.773, 'grad_norm': 4.362477779388428, 'learning_rate': 1.1603603603603603e-05, 'mean_token_accuracy': 0.7260650336742401, 'epoch': 1.26}
{'loss': 0.7829, 'grad_norm': 4.669355392456055, 'learning_rate': 1.1483483483483484e-05, 'mean_token_accuracy': 0.7306805670261383, 'epoch': 1.28}
{'loss': 0.776, 'grad_norm': 5.760852813720703, 'learning_rate': 1.1363363363363364e-05, 'mean_token_accuracy': 0.7158043026924134, 'epoch': 1.3}
{'loss': 0.7132, 'grad_norm': 4.494379043579102, 'learning_rate': 1.1243243243243245e-05, 'mean_token_accuracy': 0.7322321116924286, 'epoch': 1.32}
{'loss': 0.7512, 'grad_norm': 2.2240140438079834, 'learning_rate': 1.1123123123123123e-05, 'mean_token_accuracy': 0.7344206631183624, 'epoch': 1.33}
{'loss': 0.6818, 'grad_norm': 5.860687255859375, 'learning_rate': 1.1003003003003004e-05, 'mean_token_accuracy': 0.7375936269760132, 'epoch': 1.35}
{'loss': 0.8597, 'grad_norm': 2.816415309906006, 'learning_rate': 1.0882882882882884e-05, 'mean_token_accuracy': 0.7076036751270294, 'epoch': 1.37}
{'loss': 0.7207, 'grad_norm': 3.257821798324585, 'learning_rate': 1.0762762762762763e-05, 'mean_token_accuracy': 0.7412591338157654, 'epoch': 1.39}
{'loss': 0.7942, 'grad_norm': 5.072504997253418, 'learning_rate': 1.0642642642642644e-05, 'mean_token_accuracy': 0.7197193384170533, 'epoch': 1.41}
{'loss': 0.7478, 'grad_norm': 3.53006911277771, 'learning_rate': 1.0522522522522523e-05, 'mean_token_accuracy': 0.7303003013134003, 'epoch': 1.42}
{'loss': 0.6265, 'grad_norm': 5.490448951721191, 'learning_rate': 1.0402402402402403e-05, 'mean_token_accuracy': 0.7491324365139007, 'epoch': 1.44}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 60%|██████    | 1000/1665 [10:42<06:34,  1.69it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.8178, 'grad_norm': 3.848381757736206, 'learning_rate': 1.0282282282282284e-05, 'mean_token_accuracy': 0.7185322701931, 'epoch': 1.46}
{'loss': 0.7093, 'grad_norm': 5.668170928955078, 'learning_rate': 1.0162162162162164e-05, 'mean_token_accuracy': 0.7444282233715057, 'epoch': 1.48}
{'loss': 0.7017, 'grad_norm': 4.481324672698975, 'learning_rate': 1.0042042042042045e-05, 'mean_token_accuracy': 0.7336185693740844, 'epoch': 1.5}
{'loss': 0.7422, 'grad_norm': 2.7586677074432373, 'learning_rate': 9.921921921921923e-06, 'mean_token_accuracy': 0.7276347279548645, 'epoch': 1.51}
{'loss': 0.8195, 'grad_norm': 2.6372427940368652, 'learning_rate': 9.801801801801802e-06, 'mean_token_accuracy': 0.7143422424793243, 'epoch': 1.53}
{'loss': 0.6811, 'grad_norm': 2.689293146133423, 'learning_rate': 9.681681681681683e-06, 'mean_token_accuracy': 0.7447390854358673, 'epoch': 1.55}
{'loss': 0.8249, 'grad_norm': 3.6105334758758545, 'learning_rate': 9.561561561561562e-06, 'mean_token_accuracy': 0.7099327147006989, 'epoch': 1.57}
{'loss': 0.7762, 'grad_norm': 4.675757884979248, 'learning_rate': 9.441441441441442e-06, 'mean_token_accuracy': 0.7216369211673737, 'epoch': 1.59}
{'loss': 0.712, 'grad_norm': 3.658970594406128, 'learning_rate': 9.321321321321321e-06, 'mean_token_accuracy': 0.7365583419799805, 'epoch': 1.6}
{'loss': 0.8584, 'grad_norm': 2.492905855178833, 'learning_rate': 9.201201201201201e-06, 'mean_token_accuracy': 0.7125914931297302, 'epoch': 1.62}
{'loss': 0.6758, 'grad_norm': 4.053511619567871, 'learning_rate': 9.081081081081082e-06, 'mean_token_accuracy': 0.7444982826709747, 'epoch': 1.64}
{'loss': 0.7109, 'grad_norm': 6.08515739440918, 'learning_rate': 8.960960960960962e-06, 'mean_token_accuracy': 0.7344384074211121, 'epoch': 1.66}
{'loss': 0.7467, 'grad_norm': 4.252290725708008, 'learning_rate': 8.840840840840841e-06, 'mean_token_accuracy': 0.7265339732170105, 'epoch': 1.68}
{'loss': 0.778, 'grad_norm': 7.2312912940979, 'learning_rate': 8.720720720720722e-06, 'mean_token_accuracy': 0.7279835700988769, 'epoch': 1.69}
{'loss': 0.7254, 'grad_norm': 3.5730860233306885, 'learning_rate': 8.600600600600602e-06, 'mean_token_accuracy': 0.7332635045051574, 'epoch': 1.71}
{'loss': 0.68, 'grad_norm': 3.2684128284454346, 'learning_rate': 8.480480480480481e-06, 'mean_token_accuracy': 0.7424835741519928, 'epoch': 1.73}
{'loss': 0.8329, 'grad_norm': 3.905632734298706, 'learning_rate': 8.360360360360362e-06, 'mean_token_accuracy': 0.7129841566085815, 'epoch': 1.75}
{'loss': 0.669, 'grad_norm': 2.975369691848755, 'learning_rate': 8.24024024024024e-06, 'mean_token_accuracy': 0.7453457772731781, 'epoch': 1.77}
{'loss': 0.7184, 'grad_norm': 2.9823644161224365, 'learning_rate': 8.12012012012012e-06, 'mean_token_accuracy': 0.7291983604431153, 'epoch': 1.78}
{'loss': 0.6625, 'grad_norm': 3.0870378017425537, 'learning_rate': 8.000000000000001e-06, 'mean_token_accuracy': 0.7396601557731628, 'epoch': 1.8}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 72%|███████▏  | 1200/1665 [12:53<05:10,  1.50it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.7899, 'grad_norm': 3.3531816005706787, 'learning_rate': 7.87987987987988e-06, 'mean_token_accuracy': 0.7209336876869201, 'epoch': 1.82}
{'loss': 0.7693, 'grad_norm': 2.9012246131896973, 'learning_rate': 7.75975975975976e-06, 'mean_token_accuracy': 0.7192215383052826, 'epoch': 1.84}
{'loss': 0.6189, 'grad_norm': 4.232935905456543, 'learning_rate': 7.63963963963964e-06, 'mean_token_accuracy': 0.7513535380363464, 'epoch': 1.86}
{'loss': 0.8173, 'grad_norm': 4.425407409667969, 'learning_rate': 7.51951951951952e-06, 'mean_token_accuracy': 0.7158190786838532, 'epoch': 1.87}
{'loss': 0.7351, 'grad_norm': 4.434020042419434, 'learning_rate': 7.3993993993994e-06, 'mean_token_accuracy': 0.7263861835002899, 'epoch': 1.89}
{'loss': 0.6913, 'grad_norm': 5.183708667755127, 'learning_rate': 7.27927927927928e-06, 'mean_token_accuracy': 0.7396012604236603, 'epoch': 1.91}
{'loss': 0.7324, 'grad_norm': 2.8896894454956055, 'learning_rate': 7.159159159159161e-06, 'mean_token_accuracy': 0.7281797170639038, 'epoch': 1.93}
{'loss': 0.6573, 'grad_norm': 3.2997050285339355, 'learning_rate': 7.0390390390390395e-06, 'mean_token_accuracy': 0.7477214336395264, 'epoch': 1.95}
{'loss': 0.7495, 'grad_norm': 3.382103204727173, 'learning_rate': 6.91891891891892e-06, 'mean_token_accuracy': 0.7270008862018585, 'epoch': 1.96}
{'loss': 0.6905, 'grad_norm': 4.422109127044678, 'learning_rate': 6.798798798798799e-06, 'mean_token_accuracy': 0.7419973015785217, 'epoch': 1.98}
{'loss': 0.7409, 'grad_norm': 6.279032230377197, 'learning_rate': 6.678678678678679e-06, 'mean_token_accuracy': 0.7287874102592469, 'epoch': 2.0}
{'loss': 0.6653, 'grad_norm': 5.5850701332092285, 'learning_rate': 6.558558558558559e-06, 'mean_token_accuracy': 0.7490551888942718, 'epoch': 2.02}
{'loss': 0.7872, 'grad_norm': 3.0170834064483643, 'learning_rate': 6.4384384384384394e-06, 'mean_token_accuracy': 0.7244263887405396, 'epoch': 2.04}
{'loss': 0.7649, 'grad_norm': 4.34773063659668, 'learning_rate': 6.318318318318318e-06, 'mean_token_accuracy': 0.7276655912399292, 'epoch': 2.05}
{'loss': 0.7858, 'grad_norm': 2.9311769008636475, 'learning_rate': 6.198198198198199e-06, 'mean_token_accuracy': 0.7283541679382324, 'epoch': 2.07}
{'loss': 0.6848, 'grad_norm': 2.9646759033203125, 'learning_rate': 6.078078078078079e-06, 'mean_token_accuracy': 0.7377191126346588, 'epoch': 2.09}
{'loss': 0.6, 'grad_norm': 3.845045804977417, 'learning_rate': 5.957957957957958e-06, 'mean_token_accuracy': 0.7576027512550354, 'epoch': 2.11}
{'loss': 0.7331, 'grad_norm': 5.942415714263916, 'learning_rate': 5.837837837837839e-06, 'mean_token_accuracy': 0.7337527990341186, 'epoch': 2.13}
{'loss': 0.767, 'grad_norm': 4.5118584632873535, 'learning_rate': 5.717717717717718e-06, 'mean_token_accuracy': 0.7285105049610138, 'epoch': 2.14}
{'loss': 0.6468, 'grad_norm': 4.010150909423828, 'learning_rate': 5.597597597597598e-06, 'mean_token_accuracy': 0.7506416320800782, 'epoch': 2.16}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 84%|████████▍ | 1400/1665 [15:01<02:37,  1.68it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.6472, 'grad_norm': 3.6728122234344482, 'learning_rate': 5.4774774774774776e-06, 'mean_token_accuracy': 0.7435163795948029, 'epoch': 2.18}
{'loss': 0.6174, 'grad_norm': 3.310687780380249, 'learning_rate': 5.357357357357358e-06, 'mean_token_accuracy': 0.7575494468212127, 'epoch': 2.2}
{'loss': 0.7112, 'grad_norm': 3.9992640018463135, 'learning_rate': 5.2372372372372386e-06, 'mean_token_accuracy': 0.7462061524391175, 'epoch': 2.22}
{'loss': 0.6693, 'grad_norm': 3.6998369693756104, 'learning_rate': 5.117117117117117e-06, 'mean_token_accuracy': 0.7426183819770813, 'epoch': 2.23}
{'loss': 0.7635, 'grad_norm': 4.359856605529785, 'learning_rate': 4.996996996996997e-06, 'mean_token_accuracy': 0.7186304986476898, 'epoch': 2.25}
{'loss': 0.6432, 'grad_norm': 3.046670913696289, 'learning_rate': 4.876876876876877e-06, 'mean_token_accuracy': 0.7569181025028229, 'epoch': 2.27}
{'loss': 0.6778, 'grad_norm': 3.347581624984741, 'learning_rate': 4.756756756756757e-06, 'mean_token_accuracy': 0.7451124787330627, 'epoch': 2.29}
{'loss': 0.7136, 'grad_norm': 3.387425661087036, 'learning_rate': 4.636636636636637e-06, 'mean_token_accuracy': 0.742021232843399, 'epoch': 2.31}
{'loss': 0.5901, 'grad_norm': 4.290271759033203, 'learning_rate': 4.516516516516517e-06, 'mean_token_accuracy': 0.7581064224243164, 'epoch': 2.32}
{'loss': 0.6583, 'grad_norm': 2.762822151184082, 'learning_rate': 4.396396396396397e-06, 'mean_token_accuracy': 0.7550869107246398, 'epoch': 2.34}
{'loss': 0.756, 'grad_norm': 4.8053812980651855, 'learning_rate': 4.276276276276277e-06, 'mean_token_accuracy': 0.7287818610668182, 'epoch': 2.36}
{'loss': 0.7095, 'grad_norm': 2.876239776611328, 'learning_rate': 4.156156156156156e-06, 'mean_token_accuracy': 0.7358278751373291, 'epoch': 2.38}
{'loss': 0.6808, 'grad_norm': 5.134749412536621, 'learning_rate': 4.036036036036036e-06, 'mean_token_accuracy': 0.7390159130096435, 'epoch': 2.4}
{'loss': 0.666, 'grad_norm': 2.9220616817474365, 'learning_rate': 3.915915915915916e-06, 'mean_token_accuracy': 0.7440291941165924, 'epoch': 2.41}
{'loss': 0.6918, 'grad_norm': 3.6895933151245117, 'learning_rate': 3.795795795795796e-06, 'mean_token_accuracy': 0.7408272504806519, 'epoch': 2.43}
{'loss': 0.7442, 'grad_norm': 2.937588691711426, 'learning_rate': 3.6756756756756763e-06, 'mean_token_accuracy': 0.7219896018505096, 'epoch': 2.45}
{'loss': 0.7131, 'grad_norm': 2.6021947860717773, 'learning_rate': 3.555555555555556e-06, 'mean_token_accuracy': 0.7358503878116608, 'epoch': 2.47}
{'loss': 0.7106, 'grad_norm': 3.1616201400756836, 'learning_rate': 3.435435435435436e-06, 'mean_token_accuracy': 0.7349064648151398, 'epoch': 2.49}
{'loss': 0.6849, 'grad_norm': 3.0540730953216553, 'learning_rate': 3.3153153153153157e-06, 'mean_token_accuracy': 0.7436842143535614, 'epoch': 2.5}
{'loss': 0.5623, 'grad_norm': 3.527672529220581, 'learning_rate': 3.1951951951951953e-06, 'mean_token_accuracy': 0.7687246263027191, 'epoch': 2.52}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
 96%|█████████▌| 1600/1665 [17:10<00:39,  1.66it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.7347, 'grad_norm': 4.191553592681885, 'learning_rate': 3.0750750750750754e-06, 'mean_token_accuracy': 0.7247061252593994, 'epoch': 2.54}
{'loss': 0.6807, 'grad_norm': 3.9727609157562256, 'learning_rate': 2.954954954954955e-06, 'mean_token_accuracy': 0.7475441992282867, 'epoch': 2.56}
{'loss': 0.6571, 'grad_norm': 3.4628350734710693, 'learning_rate': 2.8348348348348347e-06, 'mean_token_accuracy': 0.7499006569385529, 'epoch': 2.58}
{'loss': 0.702, 'grad_norm': 4.003071308135986, 'learning_rate': 2.7147147147147152e-06, 'mean_token_accuracy': 0.7367524743080139, 'epoch': 2.59}
{'loss': 0.8001, 'grad_norm': 2.7541773319244385, 'learning_rate': 2.594594594594595e-06, 'mean_token_accuracy': 0.722482192516327, 'epoch': 2.61}
{'loss': 0.6777, 'grad_norm': 3.488584518432617, 'learning_rate': 2.474474474474475e-06, 'mean_token_accuracy': 0.7390617966651917, 'epoch': 2.63}
{'loss': 0.6536, 'grad_norm': 2.5852551460266113, 'learning_rate': 2.3543543543543546e-06, 'mean_token_accuracy': 0.7532364428043365, 'epoch': 2.65}
{'loss': 0.6688, 'grad_norm': 6.830456733703613, 'learning_rate': 2.2342342342342343e-06, 'mean_token_accuracy': 0.7462550401687622, 'epoch': 2.67}
{'loss': 0.7209, 'grad_norm': 2.3465330600738525, 'learning_rate': 2.1141141141141144e-06, 'mean_token_accuracy': 0.7367784559726716, 'epoch': 2.68}
{'loss': 0.6345, 'grad_norm': 5.118202209472656, 'learning_rate': 1.9939939939939944e-06, 'mean_token_accuracy': 0.7467755973339081, 'epoch': 2.7}
{'loss': 0.7674, 'grad_norm': 3.1113526821136475, 'learning_rate': 1.873873873873874e-06, 'mean_token_accuracy': 0.7363933444023132, 'epoch': 2.72}
{'loss': 0.737, 'grad_norm': 4.091163158416748, 'learning_rate': 1.7537537537537538e-06, 'mean_token_accuracy': 0.7360336780548096, 'epoch': 2.74}
{'loss': 0.6845, 'grad_norm': 5.526947498321533, 'learning_rate': 1.6336336336336336e-06, 'mean_token_accuracy': 0.7337804794311523, 'epoch': 2.76}
{'loss': 0.6702, 'grad_norm': 3.368183135986328, 'learning_rate': 1.5135135135135137e-06, 'mean_token_accuracy': 0.749098140001297, 'epoch': 2.77}
{'loss': 0.7448, 'grad_norm': 2.785741090774536, 'learning_rate': 1.3933933933933936e-06, 'mean_token_accuracy': 0.7275043249130249, 'epoch': 2.79}
{'loss': 0.6027, 'grad_norm': 2.8505430221557617, 'learning_rate': 1.2732732732732732e-06, 'mean_token_accuracy': 0.7549091815948487, 'epoch': 2.81}
{'loss': 0.7167, 'grad_norm': 3.4150328636169434, 'learning_rate': 1.1531531531531533e-06, 'mean_token_accuracy': 0.7350314021110534, 'epoch': 2.83}
{'loss': 0.6247, 'grad_norm': 3.077226161956787, 'learning_rate': 1.033033033033033e-06, 'mean_token_accuracy': 0.7527818143367767, 'epoch': 2.85}
{'loss': 0.7397, 'grad_norm': 10.048624038696289, 'learning_rate': 9.12912912912913e-07, 'mean_token_accuracy': 0.7302709758281708, 'epoch': 2.86}
{'loss': 0.6328, 'grad_norm': 9.227865219116211, 'learning_rate': 7.927927927927928e-07, 'mean_token_accuracy': 0.7463684558868409, 'epoch': 2.88}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
100%|██████████| 1665/1665 [17:59<00:00,  1.82it/s]/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
{'loss': 0.6924, 'grad_norm': 3.197892189025879, 'learning_rate': 6.726726726726727e-07, 'mean_token_accuracy': 0.7303883671760559, 'epoch': 2.9}
{'loss': 0.8824, 'grad_norm': 4.705150127410889, 'learning_rate': 5.525525525525526e-07, 'mean_token_accuracy': 0.7153911173343659, 'epoch': 2.92}
{'loss': 0.6066, 'grad_norm': 4.426590919494629, 'learning_rate': 4.324324324324325e-07, 'mean_token_accuracy': 0.7599322378635407, 'epoch': 2.94}
{'loss': 0.628, 'grad_norm': 2.467031717300415, 'learning_rate': 3.123123123123123e-07, 'mean_token_accuracy': 0.7544362902641296, 'epoch': 2.95}
{'loss': 0.6925, 'grad_norm': 3.7970798015594482, 'learning_rate': 1.921921921921922e-07, 'mean_token_accuracy': 0.7359391510486603, 'epoch': 2.97}
{'loss': 0.7087, 'grad_norm': 2.563204050064087, 'learning_rate': 7.207207207207208e-08, 'mean_token_accuracy': 0.7367108762264252, 'epoch': 2.99}
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
100%|██████████| 1665/1665 [18:08<00:00,  1.53it/s]
{'train_runtime': 1090.5802, 'train_samples_per_second': 12.205, 'train_steps_per_second': 1.527, 'train_loss': 0.8649345265494452, 'mean_token_accuracy': 0.7425359487533569, 'epoch': 3.0}
/mnt/petrelfs/majiachen/miniconda3/envs/v-oocr/lib/python3.10/site-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.
  warnings.warn("Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.")
